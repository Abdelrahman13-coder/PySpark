{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f1e8db",
   "metadata": {},
   "source": [
    "# **Labs 1 and 2 PySpark:**\n",
    "\n",
    "In these labs we will be using the \"[[NeurIPS 2020] Data Science for COVID-19 (DS4C)](https://www.kaggle.com/datasets/kimjihoo/coronavirusdataset?select=PatientInfo.csv)\" dataset, retrieved from [Kaggle](https://www.kaggle.com/) on 1/6/2022, for educational non commercial purpose, License\n",
    "[CC BY-NC-SA 4.0\n",
    "](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "\n",
    "\n",
    "The csv file that we will be using in this lab is **PatientInfo**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9bbf0",
   "metadata": {},
   "source": [
    "## PatientInfo.csv\n",
    "\n",
    "**patient_id**\n",
    "the ID of the patient\n",
    "\n",
    "**sex**\n",
    "the sex of the patient\n",
    "\n",
    "**age**\n",
    "the age of the patient\n",
    "\n",
    "**country**\n",
    "the country of the patient\n",
    "\n",
    "**province**\n",
    "the province of the patient\n",
    "\n",
    "**city**\n",
    "the city of the patient\n",
    "\n",
    "**infection_case**\n",
    "the case of infection\n",
    "\n",
    "**infected_by**\n",
    "the ID of who infected the patient\n",
    "\n",
    "\n",
    "**contact_number**\n",
    "the number of contacts with people\n",
    "\n",
    "**symptom_onset_date**\n",
    "the date of symptom onset\n",
    "\n",
    "**confirmed_date**\n",
    "the date of being confirmed\n",
    "\n",
    "**released_date**\n",
    "the date of being released\n",
    "\n",
    "**deceased_date**\n",
    "the date of being deceased\n",
    "\n",
    "**state**\n",
    "isolated / released / deceased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b6f619",
   "metadata": {},
   "source": [
    "### Import the pyspark and check it's version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fe2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0fc8e",
   "metadata": {},
   "source": [
    "### Import and create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94904228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/26 12:15:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56234220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356d68d",
   "metadata": {},
   "source": [
    "### Load the PatientInfo.csv file and show the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5185728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9555e7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|patient_id|   sex|age|country|province|        city|      infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|1000000001|  male|50s|  Korea|   Seoul|  Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|    2020-01-23|   2020-02-05|         null|released|\n",
      "|1000000002|  male|30s|  Korea|   Seoul| Jungnang-gu|     overseas inflow|       null|            31|              null|    2020-01-30|   2020-03-02|         null|released|\n",
      "|1000000003|  male|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 2002000001|            17|              null|    2020-01-30|   2020-02-19|         null|released|\n",
      "|1000000004|  male|20s|  Korea|   Seoul|     Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|    2020-01-30|   2020-02-15|         null|released|\n",
      "|1000000005|female|20s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000002|             2|              null|    2020-01-31|   2020-02-24|         null|released|\n",
      "|1000000006|female|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|            43|              null|    2020-01-31|   2020-02-19|         null|released|\n",
      "|1000000007|  male|20s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|             0|              null|    2020-01-31|   2020-02-10|         null|released|\n",
      "|1000000008|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-02|   2020-02-24|         null|released|\n",
      "|1000000009|  male|30s|  Korea|   Seoul|   Songpa-gu|     overseas inflow|       null|            68|              null|    2020-02-05|   2020-02-21|         null|released|\n",
      "|1000000010|female|60s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000003|             6|              null|    2020-02-05|   2020-02-29|         null|released|\n",
      "|1000000011|female|50s|  China|   Seoul|Seodaemun-gu|     overseas inflow|       null|            23|              null|    2020-02-06|   2020-02-29|         null|released|\n",
      "|1000000012|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-07|   2020-02-27|         null|released|\n",
      "|1000000013|  male|80s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|           117|              null|    2020-02-16|         null|         null|deceased|\n",
      "|1000000014|female|60s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000013|            27|        2020-02-06|    2020-02-16|   2020-03-12|         null|released|\n",
      "|1000000015|  male|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT|       null|             8|        2020-02-11|    2020-02-19|         null|         null|released|\n",
      "|1000000016|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|          null|              null|    2020-02-19|   2020-03-11|         null|released|\n",
      "|1000000017|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|          null|              null|    2020-02-20|   2020-03-01|         null|released|\n",
      "|1000000018|  male|20s|  Korea|   Seoul|         etc|                 etc|       null|          null|              null|    2020-02-20|         null|         null|released|\n",
      "|1000000019|female|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000021|          null|              null|    2020-02-20|   2020-03-08|         null|released|\n",
      "|1000000020|female|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT| 1000000015|          null|              null|    2020-02-20|         null|         null|released|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format('csv')\n",
    "          .option('inferSchema','true')\n",
    "          .option('header','true')\n",
    "          .load('PatientInfo.csv')\n",
    "         )\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43bdca",
   "metadata": {},
   "source": [
    "### Display the schema of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51a2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patient_id: long (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- infection_case: string (nullable = true)\n",
      " |-- infected_by: string (nullable = true)\n",
      " |-- contact_number: string (nullable = true)\n",
      " |-- symptom_onset_date: string (nullable = true)\n",
      " |-- confirmed_date: string (nullable = true)\n",
      " |-- released_date: string (nullable = true)\n",
      " |-- deceased_date: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114e1dd",
   "metadata": {},
   "source": [
    "### Display the statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d63947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+----+----------+--------+--------------+--------------------+--------------------+--------------------+------------------+--------------+-------------+-------------+--------+\n",
      "|summary|          patient_id|   sex| age|   country|province|          city|      infection_case|         infected_by|      contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+-------+--------------------+------+----+----------+--------+--------------+--------------------+--------------------+--------------------+------------------+--------------+-------------+-------------+--------+\n",
      "|  count|                5165|  4043|3785|      5165|    5165|          5071|                4246|                1346|                 791|               690|          5162|         1587|           66|    5165|\n",
      "|   mean|2.8636345618679576E9|  null|null|      null|    null|          null|                null|2.2845944015643125E9|1.6772572523506988E7|              null|          null|         null|         null|    null|\n",
      "| stddev| 2.074210725277473E9|  null|null|      null|    null|          null|                null|1.5265072953383324E9| 3.093097580985502E8|              null|          null|         null|         null|    null|\n",
      "|    min|          1000000001|female|  0s|Bangladesh|   Busan|     Andong-si|Anyang Gunpo Past...|          1000000002|                   -|                  |    2020-01-20|   2020-02-05|   2020-02-19|deceased|\n",
      "|    max|          7000000019|  male| 90s|   Vietnam|   Ulsan|sankyeock-dong|     overseas inflow|          7000000009|                  95|        2020-06-28|    2020-06-30|   2020-06-28|   2020-05-25|released|\n",
      "+-------+--------------------+------+----+----------+--------+--------------+--------------------+--------------------+--------------------+------------------+--------------+-------------+-------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78859b9",
   "metadata": {},
   "source": [
    "### Using the state column.\n",
    "### How many people survived (released), and how many didn't survive (isolated/deceased)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5316dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|   state|count(state)|\n",
      "+--------+------------+\n",
      "|isolated|        2158|\n",
      "|released|        2929|\n",
      "|deceased|          78|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select('state')\n",
    "   .groupBy('state')\n",
    "   .agg(F.count(\"state\"))\n",
    "  ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c16346",
   "metadata": {},
   "source": [
    "### Display the number of null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adc0ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+-------+--------+----+--------------+-----------+--------------+------------------+--------------+-------------+-------------+-----+\n",
      "|patient_id| sex| age|country|province|city|infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|state|\n",
      "+----------+----+----+-------+--------+----+--------------+-----------+--------------+------------------+--------------+-------------+-------------+-----+\n",
      "|         0|1122|1380|      0|       0|  94|           919|       3819|          4374|              4475|             3|         3578|         5099|    0|\n",
      "+----------+----+----+-------+--------+----+--------------+-----------+--------------+------------------+--------------+-------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find Count of Null, None, NaN of All DataFrame Columns\n",
    "#from pyspark.sql.functions import col,isnan, when, count\n",
    "df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3133f5a",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec32fa0c",
   "metadata": {},
   "source": [
    "### Fill the nulls in the deceased_date with the released_date. \n",
    "- You can use <b>coalesce</b> function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ba64f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|deceased_date|released_date|\n",
      "+-------------+-------------+\n",
      "|   2020-02-05|   2020-02-05|\n",
      "|   2020-03-02|   2020-03-02|\n",
      "|   2020-02-19|   2020-02-19|\n",
      "|   2020-02-15|   2020-02-15|\n",
      "|   2020-02-24|   2020-02-24|\n",
      "|   2020-02-19|   2020-02-19|\n",
      "|   2020-02-10|   2020-02-10|\n",
      "|   2020-02-24|   2020-02-24|\n",
      "|   2020-02-21|   2020-02-21|\n",
      "|   2020-02-29|   2020-02-29|\n",
      "|   2020-02-29|   2020-02-29|\n",
      "|   2020-02-27|   2020-02-27|\n",
      "|         null|         null|\n",
      "|   2020-03-12|   2020-03-12|\n",
      "|         null|         null|\n",
      "|   2020-03-11|   2020-03-11|\n",
      "|   2020-03-01|   2020-03-01|\n",
      "|         null|         null|\n",
      "|   2020-03-08|   2020-03-08|\n",
      "|         null|         null|\n",
      "+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('deceased_date',F.coalesce('deceased_date','released_date'))\n",
    "df.select('deceased_date','released_date').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec324f5",
   "metadata": {},
   "source": [
    "### Add a column named no_days which is difference between the deceased_date and the confirmed_date then show the top 5 rows. Print the schema.\n",
    "- <b> Hint: You need to typecast these columns as date first <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d065e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('no_days',F.datediff(df['deceased_date'],df['confirmed_date']))\n",
    "#f.select('no_days').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b2466",
   "metadata": {},
   "source": [
    "### Add a is_male column if male then it should yield true, else then False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8efe03b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|is_male|\n",
      "+-------+\n",
      "|   True|\n",
      "|   True|\n",
      "|   True|\n",
      "|   True|\n",
      "|  False|\n",
      "|  False|\n",
      "|   True|\n",
      "|   True|\n",
      "|   True|\n",
      "|  False|\n",
      "|  False|\n",
      "|   True|\n",
      "|   True|\n",
      "|  False|\n",
      "|   True|\n",
      "|   True|\n",
      "|   True|\n",
      "|   True|\n",
      "|  False|\n",
      "|  False|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"is_male\",F.when(df.sex == \"male\",\"True\")\n",
    "                             .otherwise(\"False\"))\n",
    "df.select('is_male').show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603d7c0",
   "metadata": {},
   "source": [
    "### Add a is_dead column if patient state is not released then it should yield true, else then False\n",
    "\n",
    "- Use <b>UDF</b> to perform this task. \n",
    "- However, UDF is not recommended there is no built in function can do the required operation.\n",
    "- UDF is slower than built in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb7055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import BooleanType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe2d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertUdf(x):\n",
    "    if x != \"released\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3343075",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertUDF = F.udf(lambda x: convertUdf(x), BooleanType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230a09e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|is_dead|\n",
      "+-------+\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|   true|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "|  false|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('is_dead',convertUDF('state'))\n",
    "df.select('is_dead').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15264a9",
   "metadata": {},
   "source": [
    "### Change the ages to bins from 10s, 0s, 10s, 20s,.etc to 0,10, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2b57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_S(x):\n",
    "#     return x.replace('s',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b700ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_s_UDF = F.udf(lambda x: remove_S(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e33860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "091de102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 50|\n",
      "| 30|\n",
      "| 50|\n",
      "| 20|\n",
      "| 20|\n",
      "| 50|\n",
      "| 20|\n",
      "| 20|\n",
      "| 30|\n",
      "| 60|\n",
      "| 50|\n",
      "| 20|\n",
      "| 80|\n",
      "| 60|\n",
      "| 70|\n",
      "| 70|\n",
      "| 70|\n",
      "| 20|\n",
      "| 70|\n",
      "| 70|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('age',regexp_replace('age', 's', ''))\n",
    "df.select('age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cdf846",
   "metadata": {},
   "source": [
    "### Change age, and no_days  to be typecasted as Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfea7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('age', df.age.cast('double'))\n",
    "df = df.withColumn('no_days',df.no_days.cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e3a87",
   "metadata": {},
   "source": [
    "### Drop the columns\n",
    "[\"patient_id\",\"sex\",\"infected_by\",\"contact_number\",\"released_date\",\"state\",\n",
    "\"symptom_onset_date\",\"confirmed_date\",\"deceased_date\",\"country\",\"no_days\",\n",
    "\"city\",\"infection_case\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ae0c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"patient_id\",\"sex\",\"infected_by\",\"contact_number\",\"released_date\",\"state\", \"symptom_onset_date\",\"confirmed_date\",\"deceased_date\",\"country\",\"no_days\", \"city\",\"infection_case\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f0ceeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- is_male: string (nullable = false)\n",
      " |-- is_dead: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df47a6",
   "metadata": {},
   "source": [
    "### Recount the number of nulls now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d66eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "#    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71f158",
   "metadata": {},
   "source": [
    "## Now do the same but using SQL select statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d540282",
   "metadata": {},
   "source": [
    "### From the original Patient DataFrame, Create a temporary view (table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf56099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.read.csv('PatientInfo.csv',\n",
    "                   header=True,\n",
    "                       )\n",
    "df_sql.createOrReplaceTempView(\"patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb004277",
   "metadata": {},
   "source": [
    "### Use SELECT statement to select all columns from the dataframe and show the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12ae8226",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|patient_id|   sex|age|country|province|        city|      infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|1000000001|  male|50s|  Korea|   Seoul|  Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|    2020-01-23|   2020-02-05|         null|released|\n",
      "|1000000002|  male|30s|  Korea|   Seoul| Jungnang-gu|     overseas inflow|       null|            31|              null|    2020-01-30|   2020-03-02|         null|released|\n",
      "|1000000003|  male|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 2002000001|            17|              null|    2020-01-30|   2020-02-19|         null|released|\n",
      "|1000000004|  male|20s|  Korea|   Seoul|     Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|    2020-01-30|   2020-02-15|         null|released|\n",
      "|1000000005|female|20s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000002|             2|              null|    2020-01-31|   2020-02-24|         null|released|\n",
      "|1000000006|female|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|            43|              null|    2020-01-31|   2020-02-19|         null|released|\n",
      "|1000000007|  male|20s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|             0|              null|    2020-01-31|   2020-02-10|         null|released|\n",
      "|1000000008|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-02|   2020-02-24|         null|released|\n",
      "|1000000009|  male|30s|  Korea|   Seoul|   Songpa-gu|     overseas inflow|       null|            68|              null|    2020-02-05|   2020-02-21|         null|released|\n",
      "|1000000010|female|60s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000003|             6|              null|    2020-02-05|   2020-02-29|         null|released|\n",
      "|1000000011|female|50s|  China|   Seoul|Seodaemun-gu|     overseas inflow|       null|            23|              null|    2020-02-06|   2020-02-29|         null|released|\n",
      "|1000000012|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-07|   2020-02-27|         null|released|\n",
      "|1000000013|  male|80s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|           117|              null|    2020-02-16|         null|         null|deceased|\n",
      "|1000000014|female|60s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000013|            27|        2020-02-06|    2020-02-16|   2020-03-12|         null|released|\n",
      "|1000000015|  male|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT|       null|             8|        2020-02-11|    2020-02-19|         null|         null|released|\n",
      "|1000000016|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|          null|              null|    2020-02-19|   2020-03-11|         null|released|\n",
      "|1000000017|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|          null|              null|    2020-02-20|   2020-03-01|         null|released|\n",
      "|1000000018|  male|20s|  Korea|   Seoul|         etc|                 etc|       null|          null|              null|    2020-02-20|         null|         null|released|\n",
      "|1000000019|female|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000021|          null|              null|    2020-02-20|   2020-03-08|         null|released|\n",
      "|1000000020|female|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT| 1000000015|          null|              null|    2020-02-20|         null|         null|released|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT *\n",
    "             FROM patients\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da4318",
   "metadata": {},
   "source": [
    "### *Using SQL commands*, limit the output to only 5 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97911bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|patient_id|   sex|age|country|province|       city|      infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|1000000001|  male|50s|  Korea|   Seoul| Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|    2020-01-23|   2020-02-05|         null|released|\n",
      "|1000000002|  male|30s|  Korea|   Seoul|Jungnang-gu|     overseas inflow|       null|            31|              null|    2020-01-30|   2020-03-02|         null|released|\n",
      "|1000000003|  male|50s|  Korea|   Seoul|  Jongno-gu|contact with patient| 2002000001|            17|              null|    2020-01-30|   2020-02-19|         null|released|\n",
      "|1000000004|  male|20s|  Korea|   Seoul|    Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|    2020-01-30|   2020-02-15|         null|released|\n",
      "|1000000005|female|20s|  Korea|   Seoul|Seongbuk-gu|contact with patient| 1000000002|             2|              null|    2020-01-31|   2020-02-24|         null|released|\n",
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT *\n",
    "          FROM patients\n",
    "          LIMIT(5)\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70edf17",
   "metadata": {},
   "source": [
    "### Select the count of males and females in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00e9fd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|   sex|count(sex)|\n",
      "+------+----------+\n",
      "|  null|         0|\n",
      "|female|      2218|\n",
      "|  male|      1825|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT sex,count(sex)\n",
    "          FROM patients\n",
    "          GROUP BY sex\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73683674",
   "metadata": {},
   "source": [
    "### How many people did survive, and how many didn't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e5a3908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|   state|count(state)|\n",
      "+--------+------------+\n",
      "|isolated|        2158|\n",
      "|released|        2929|\n",
      "|deceased|          78|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT state,count(state)\n",
    "          FROM patients\n",
    "          GROUP BY state\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4424228",
   "metadata": {},
   "source": [
    "### Now, let's perform some preprocessing using SQL:\n",
    "1. Convert *age* column to double after removing the 's' at the end -- *hint: check SUBSTRING method*\n",
    "2. Select only the following columns: `['sex', 'age', 'province', 'state']`\n",
    "3. Store the result of the query in a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16994e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|substring(age, 1, 2)|\n",
      "+--------------------+\n",
      "|                50.0|\n",
      "|                30.0|\n",
      "|                50.0|\n",
      "|                20.0|\n",
      "|                20.0|\n",
      "|                50.0|\n",
      "|                20.0|\n",
      "|                20.0|\n",
      "|                30.0|\n",
      "|                60.0|\n",
      "|                50.0|\n",
      "|                20.0|\n",
      "|                80.0|\n",
      "|                60.0|\n",
      "|                70.0|\n",
      "|                70.0|\n",
      "|                70.0|\n",
      "|                20.0|\n",
      "|                70.0|\n",
      "|                70.0|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"\"\"\n",
    "          SELECT double(SUBSTRING(age,1,2))\n",
    "          FROM patients;\n",
    "          \n",
    "          \"\"\")\n",
    "# df_sql = spark.sql(\"\"\"\n",
    "#                    ALTER TABLE patients modify column age DOUBLE;\n",
    "#                    \"\"\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3cf4f0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------+--------+\n",
      "|   sex|age|province|   state|\n",
      "+------+---+--------+--------+\n",
      "|  male|50s|   Seoul|released|\n",
      "|  male|30s|   Seoul|released|\n",
      "|  male|50s|   Seoul|released|\n",
      "|  male|20s|   Seoul|released|\n",
      "|female|20s|   Seoul|released|\n",
      "|female|50s|   Seoul|released|\n",
      "|  male|20s|   Seoul|released|\n",
      "|  male|20s|   Seoul|released|\n",
      "|  male|30s|   Seoul|released|\n",
      "|female|60s|   Seoul|released|\n",
      "|female|50s|   Seoul|released|\n",
      "|  male|20s|   Seoul|released|\n",
      "|  male|80s|   Seoul|deceased|\n",
      "|female|60s|   Seoul|released|\n",
      "|  male|70s|   Seoul|released|\n",
      "|  male|70s|   Seoul|released|\n",
      "|  male|70s|   Seoul|released|\n",
      "|  male|20s|   Seoul|released|\n",
      "|female|70s|   Seoul|released|\n",
      "|female|70s|   Seoul|released|\n",
      "+------+---+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_sql = spark.sql(\"\"\"\n",
    "                    SELECT sex, age, province, state\n",
    "                    FROM patients\n",
    "                    \"\"\")\n",
    "new_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a24c24",
   "metadata": {},
   "source": [
    "## Machine Learning \n",
    "### Create a pipeline model to predict is_dead and evaluate the performance.\n",
    "- Use <b>StringIndexer</b> to transform <b>string</b> data type to indices.\n",
    "- Use <b>OneHotEncoder</b> to deal with categorical values.\n",
    "- Use <b>Imputer</b> to fill missing data with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b85697cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('is_dead',df.is_dead.cast('Integer'))\n",
    "# df = df.withColumn('age', df.age.cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "272b1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|is_dead| age|\n",
      "+-------+----+\n",
      "|      0|50.0|\n",
      "|      0|30.0|\n",
      "|      0|50.0|\n",
      "|      0|20.0|\n",
      "|      0|20.0|\n",
      "|      0|50.0|\n",
      "|      0|20.0|\n",
      "|      0|20.0|\n",
      "|      0|30.0|\n",
      "|      0|60.0|\n",
      "|      0|50.0|\n",
      "|      0|20.0|\n",
      "|      1|80.0|\n",
      "|      0|60.0|\n",
      "|      0|70.0|\n",
      "|      0|70.0|\n",
      "|      0|70.0|\n",
      "|      0|20.0|\n",
      "|      0|70.0|\n",
      "|      0|70.0|\n",
      "+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('is_dead','age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc1f6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder,VectorAssembler, Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "209f58d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['province', 'is_male']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = [field for (field,dataType) in df.dtypes if ((dataType == 'string')&(field!='is_dead'))]\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d7ecd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['province_Index', 'is_male_Index']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_output = [s + \"_Index\" for s in categorical_cols]\n",
    "categorical_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88673152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['province_ohe', 'is_male_ohe']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_encoded = [s + \"_ohe\" for s in categorical_cols]\n",
    "categorical_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c4be148",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=categorical_cols, outputCols= categorical_output,handleInvalid = 'skip')\n",
    "\n",
    "ohe = OneHotEncoder(inputCols= categorical_output, outputCols= categorical_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a24c0e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = [field for (field, dataType) in df.dtypes\n",
    "                 if dataType in ['int','double'] and field != 'is_dead']\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad8e775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_cols =  [x + \"imputed\" for x in numerical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47879d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy='mean', inputCols=numerical_cols, outputCols=imputed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f8579f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ageimputed', 'province_ohe', 'is_male_ohe']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInputs = imputed_cols + categorical_encoded\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "197beebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33b172cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_d46bdc7e5574"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31ef87",
   "metadata": {},
   "source": [
    "### Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51c2c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3e95d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(featuresCol='features',\n",
    "                              labelCol='is_dead',\n",
    "                              predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4dc29138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol='features',\n",
    "                        labelCol='is_dead',\n",
    "                        predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c281a",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e7f4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "trainDF, testDF = df.randomSplit([0.8,0.2],seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a6910",
   "metadata": {},
   "source": [
    "### Create a Pipeline Logestic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a603d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStages = [stringIndexer, ohe, imputer, vecAssembler,lr]\n",
    "pipeline = Pipeline(stages=myStages)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1782f3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------+-------+--------------+-------------+---------------+-------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "| age|   province|is_male|is_dead|province_Index|is_male_Index|   province_ohe|  is_male_ohe|        ageimputed|            features|       rawPrediction|         probability|prediction|\n",
      "+----+-----------+-------+-------+--------------+-------------+---------------+-------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "|null| Gangwon-do|  False|      0|          10.0|          0.0|(16,[10],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,11,17],[40...|[0.74231117298496...|[0.67750103925742...|       0.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "|null|Gyeonggi-do|  False|      1|           2.0|          0.0| (16,[2],[1.0])|(1,[0],[1.0])|40.085978835978835|(18,[0,3,17],[40....|[-3.1704535654030...|[0.04029287268268...|       1.0|\n",
      "+----+-----------+-------+-------+--------------+-------------+---------------+-------------+------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e57b9f",
   "metadata": {},
   "source": [
    "### Model Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "366ef900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "regeval_acc = MulticlassClassificationEvaluator(predictionCol='prediction',labelCol='is_dead', metricName = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9adf7181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268268268268268"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regeval_acc.evaluate(predDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10f9530",
   "metadata": {},
   "source": [
    "### Pipeline for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bc71545",
   "metadata": {},
   "outputs": [],
   "source": [
    "myStages = [stringIndexer, ohe, imputer, vecAssembler,tree]\n",
    "pipeline = Pipeline(stages=myStages)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "predDF_tree = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39d8757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_eval_acc = MulticlassClassificationEvaluator(predictionCol='prediction',labelCol='is_dead', metricName = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed9fbc",
   "metadata": {},
   "source": [
    "### Decision tree evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1344cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378378378378378"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_eval_acc.evaluate(predDF_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5023b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
